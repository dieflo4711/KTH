from scipy.optimize import minimize
import matplotlib.pyplot as plt
import numpy as np
import random, math


def kernel(d1, d2, type = 'lin'):
    if type == 'lin':
        return np.dot(d1, d2)
    elif type == 'poly':
        p = 3
        return (np.dot(d1, d2) + 1.0) ** p
    else:
        sigma = 0.5
        return math.exp(-(np.linalg.norm(d1 - d2) ** 2) / (2 * (sigma ** 2)))

def compute_p(targets, inputs, N):
    matrix = np.zeros((N, N))
    for i in range(N):
        for j in range(N):
            matrix[i][j] = targets[i] * targets[j] * kernel(inputs[i], inputs[j], 'poly')
    return matrix

def objective(alpha):
    val = 0
    for i in range(N):
        for j in range(N):
            val += alpha[i] * alpha[j] * p[i][j]
    return (val/2.0) - np.sum(alpha)

def zerofun(alpha):
    return np.dot(alpha, targets)

def non_zero(alpha, inputs, targets):
    alphas_ = []
    inputs_ = []
    targets_ = []

    for i in range(len(alpha)):
        if alpha[i] > 10 ** -5:
            alphas_.append(alpha[i])
            inputs_.append(inputs[i])
            targets_.append(targets[i])
    return alphas_, inputs_, targets_

def get_b(alphas_, inputs_, targets_, C):
    val = 0
    idx = 0
    for k in range(len(alphas_)):
        if C != None:
            if alphas_[k] < C:
                idx = k
        else:
            idx = 0
    for i in range(len(alphas_)):
        val += alphas_[i]*targets_[i]*kernel(inputs_[idx], inputs_[i],'poly')
    return val - targets_[idx]

def indicator(s, b, alphas_, inputs_, targets_):
    val = 0
    for i in range(len(alphas_)):
        val += alphas_[i]*targets_[i]*kernel(s, inputs_[i],'poly')
    return val - b

if __name__ == '__main__':
    np.random.seed(100)

    classA = np.concatenate((np.random.randn(10, 2) * 0.7 + [1.0, 0.0], np.random.randn(10, 2) * 0.5 + [-0.2, -0.2]))
    classA = np.concatenate((classA, np.random.randn(10, 2) * 0.7 + [1.8, -1.8]))
    classB = np.concatenate((np.random.randn(20, 2) * 0.5 + [0.3, -1.4], np.random.randn(20, 2) * 0.5 + [-0.4, -1.5]))

    inputs = np.concatenate((classA, classB))
    targets = np.concatenate((np.ones(classA.shape[0]), -np.ones(classB.shape[0])))

    N = inputs.shape[0]  # Number of rows ( samples )
    permute = list(range(N))
    random.shuffle(permute)
    inputs = inputs[permute, :]  # data
    targets = targets[permute]  # t

    p = compute_p(targets, inputs, N)
    C = 1 #5
    B = [(0, C) for b in range(N)]
    start = np.zeros(N)
    XC = {'type': 'eq', 'fun': zerofun}

    ret = minimize(objective, start, bounds=B, constraints=XC)

    if ret['success'] == False:
        print('Ret failure')

    alpha = ret['x']

    alphas_, inputs_, targets_ = non_zero(alpha, inputs, targets)

    b = get_b(alphas_, inputs_, targets_, C)

    xgrid = np.linspace(-5, 5)
    ygrid = np.linspace(-4, 4)

    grid = np.array([[indicator([x, y], b, alphas_, inputs_, targets_) for x in xgrid] for y in ygrid])
    plt.contour(xgrid, ygrid, grid, (-1.0, 0.0, 1.0), colors=('red', 'black', 'blue'), linewidths=(1, 3, 1))

    plt.plot([p[0] for p in classA], [p[1] for p in classA], 'b.')
    plt.plot([p[0] for p in classB], [p[1] for p in classB], 'r.')

    plt.axis('equal')
    #plt.savefig('svmplot.pdf')
    plt.show()

